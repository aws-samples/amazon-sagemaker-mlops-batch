{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c41240-c6cd-4dce-882d-770a8f0eea33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker Model Monitor (data quality) for SageMaker Batch Transform Jobs - Model Training & Baselining Pipeline\n",
    "![Demo Scope](images/AIM321-Batch-Lifecycle-Overview.jpg)\n",
    "\n",
    "![Demo Scope](images/AIM321-Demo-Scenario-Overview-1.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967670f-22f7-40c1-aed6-708ce81bf0f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment if not using latest version of SageMaker SDK\n",
    "#import sys\n",
    "\n",
    "#! pip install --upgrade pip\n",
    "#!{sys.executable} -m pip install sagemaker==2.114.0\n",
    "#!{sys.executable} -m pip install -U boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acef961-5c67-43c5-84cc-504a27a2207a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you run this notebook in SageMaker Studio, you need to make sure latest python SDK is installed and restart the kernel, \n",
    "# so please uncomment the code below, and run it.\n",
    "#import IPython\n",
    "#IPython.Application.instance().kernel.do_shutdown(True)  # has to restart kernel so changes are used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c44bed-5dc1-452f-b383-2a7366ccc8e4",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "In this section, we'll import libraries and setup variables needed to configure pipeline steps and construct the model build pipeline. We'll also upload the scripts that will be used for the data preprocessing and model evaluation steps to S3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaadc74-5506-4185-bd91-1dcb2b5987a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# SageMaker Job Imports (ex. Processing, Training) \n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.model_monitor import DatasetFormat, model_monitoring\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig\n",
    ")\n",
    "\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "\n",
    "# SageMaker Pipeline Imports \n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep, TransformStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    DataBiasCheckConfig,\n",
    "    ClarifyCheckStep,\n",
    ")\n",
    "from sagemaker.workflow.quality_check_step import (\n",
    "    DataQualityCheckConfig,\n",
    "    QualityCheckStep,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterBoolean,\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be9dbd-4467-400a-b6d7-89bbf7cadb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SageMaker variables\n",
    "session = PipelineSession()\n",
    "bucket = session.default_bucket()\n",
    "role_arn= sagemaker.get_execution_role()\n",
    "region = session.boto_region_name\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "aws_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411aa33-dabf-436a-af20-c49e8e5c75ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup S3 paths for pipeline inputs, outputs, & artifacts\n",
    "print(\"Demo Bucket: {}\".format(bucket))\n",
    "bucket_prefix = f\"aim321-demo-model-monitor-batch-transform/{int(time.time())}\"\n",
    "model_artifacts = \"s3://{}/{}/model-artifacts\".format(bucket,bucket_prefix)\n",
    "transformed_data_path = \"s3://{}/{}/transformed-data\".format(bucket, bucket_prefix)\n",
    "raw_input_data = \"s3://{}/aim321-demo-model-monitor-batch-transform/raw-customer-data/20221122/churn-dataset.csv\".format(bucket) \n",
    "\n",
    "print(\"Raw Data Path: {}\".format(raw_input_data))\n",
    "print(\"Transformed Data Path: {}\".format(transformed_data_path))\n",
    "print(\"Model Artifact Path: {}\".format(model_artifacts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95220e6f-f5f0-4bf5-b4ba-1fbf60290daf",
   "metadata": {},
   "source": [
    "### SageMaker Model Registry\n",
    "\n",
    "Specify the model package group for registering high performing model versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da14f4-c5ac-438e-a0da-915514ae05d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_group_name=\"aim321-customer-churn\"\n",
    "\n",
    "print(\"SageMaker Model Registry - Model Package Group:\", model_package_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53bb502-1354-4f58-94f4-c3a4278a2452",
   "metadata": {},
   "source": [
    "### Setup Step Caching Configuration\n",
    "\n",
    "This configuration can be enabled on pipeline steps to allow SageMaker Pipelines to automatically check if a previous (successful) run of a pipeline step with the same values for specific parameters is found. If it is found, Pipelines propogates the results of that step to the next step without re-running the step saving both time and compute costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226b10d-6297-4fd7-b873-84a6227a123f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT12H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5363796e-1d3a-4a62-944f-4320290acf9e",
   "metadata": {},
   "source": [
    "### Setup Runtime Parameters\n",
    "\n",
    "Configurable parameters that can be passed in at runtime without changing pipeline code. \n",
    "\n",
    "            pipeline.start(parameters=dict(...))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0b1bd-0343-449c-ad5a-3a16c635c593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Runtime Parameters \n",
    "\n",
    "# Data Preparation Step - S3 URI to input data\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\", \n",
    "    default_value=raw_input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ae01e-f568-4dfc-9e23-361887e96210",
   "metadata": {},
   "source": [
    "Train and baseline pipeline is part 1 of the batch inference with data quality model monitoring using SageMaker Pipelines. The necessary steps and code are within 1.SageMakerPipeline-BaselineData-Train.ipynb. Train and baseline pipeline takes the raw customer churn data as input, and generates baseline and the trained model which will be registered with the model registry for subsequent use with Batch Transform.\n",
    "\n",
    "1-A. Configure Model Build Pipeline\n",
    "1. Prepare Data Step\n",
    "2. Train Model Step\n",
    "3. Evaluate Model Step\n",
    "\n",
    "1-B. Configure Steps to Baseline, Package & Register Model Version\n",
    "1. Baseline Step for Data Drift Model Monitor\n",
    "2. Package Model Step\n",
    "3. Register Model Step\n",
    "\n",
    "1-C. Conditional Step: Configure step to evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff366b-54a5-4ede-809f-7f7fbbcc6272",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "### 1-A Configure Model Build & Baseline Pipeline Steps\n",
    "\n",
    "Model build pipeline is a three step process, \n",
    "\n",
    "1. Prepare Data Step\n",
    "2. Train Model Step\n",
    "3. Evaluate Model Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24364524-e527-4f0e-88a6-8a97c3984bce",
   "metadata": {},
   "source": [
    "![Step1](./images/AIM321-Model-Build-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e1790-0fd8-4243-82dc-fc6259f5bc4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Prepare Data Step: Configure Processing Job & Pipeline Step\n",
    "\n",
    "Prepare data step is the first part of the three parts of model build pipeline which involves pre-processing the raw data and preparing it for training and evaluation. For processing, prepare data step uses SKLearnProcessor container. It allows to select the appropriate instance type and instance count for processing the data. Depending on the size of the data, the instance type can be changed to smaller or larger instance type. Prepare data is a [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) and utilizes *preprocessing.py* script. It reads the raw data from designated S3 bucket as input using ProcessingInput, does the necessary data processing as per the logic within *preprocessing.py*. Since *preprocessing.py* has logic for converting categorical variables from the raw data into dummy variables, this logic substantially increases number of columns as feature engineering.  It also splits the data into 3 parts for training, validation, testing. Prepare data step then writes the 3 datasets as output using ProcessingOutput to designated folders in S3. These 3 datasets are inputs for train model step and Evaluate Model Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74b94b-c799-440e-bafe-2a2b18698483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure SageMaker Processing Job\n",
    "preprocess_data_processor = SKLearnProcessor(\n",
    "    framework_version='1.0-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    base_job_name='aim321-data-preparation',\n",
    ")\n",
    "# Configure Pipeline Step - 'ProcessingStep'\n",
    "data_preparation_step = ProcessingStep(\n",
    "    name='PrepareData',\n",
    "    processor=preprocess_data_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data,\n",
    "            destination='/opt/ml/processing/input'\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='train',\n",
    "            destination=f'{transformed_data_path}/train',\n",
    "            source='/opt/ml/processing/train'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='validation',\n",
    "            destination=f'{transformed_data_path}/validation',\n",
    "            source='/opt/ml/processing/validation'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='test',\n",
    "            destination=f'{transformed_data_path}/test',\n",
    "            source='/opt/ml/processing/test'\n",
    "        )\n",
    "    ],\n",
    "    code=\"s3://{}/aim321-demo-model-monitor-batch-transform/scripts/preprocessing.py\".format(bucket),\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8412cc0-ef61-4861-a583-5203de451bbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Train Model Step: Configure Training Job & Pipeline Step\n",
    "\n",
    "Train model step is the second part of the three parts of model build pipeline which involves training the appropriate model. Based on the target variable of the dataset, it is a binary classification problem. XGBoost model is selected for this, for which xgboost container is utilized for training. Train model step is [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) within pipeline and takes train and validation data from prepare data set as part of TrainingInput. Train model step trains the xgboost model and saves the model in S3 bucket as *model.tar.gz* file. *model.tar.gz* file is an essential file which will be utilized as next steps for evaluate model step and for model registry later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c723a9-f4da-4459-8d80-83a694b8b69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure SageMaker Training Job\n",
    "\n",
    "xgboost_container = sagemaker.image_uris.retrieve(framework=\"xgboost\",region=region,version=\"1.0-1\",py_version=\"py3\",)\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_container, \n",
    "    role=role_arn,\n",
    "    output_path=f'{model_artifacts}',\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.2xlarge', \n",
    "    volume_size=5, # 5 GB \n",
    ")\n",
    "\n",
    "# Tuned hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=48,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    silent=0,\n",
    ")\n",
    "# Configure Pipeline Step - 'TrainingStep'\n",
    "training_step = TrainingStep(\n",
    "    name='TrainModel',\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=data_preparation_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=data_preparation_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e44569-6c9d-4f8a-a93f-8768e95b9932",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Evaluate Model Step: Configure Processing Job & Pipeline Step\n",
    "\n",
    "Evaluate model step is the last step of the of the three parts of model build pipeline and involves evaluating the trained model with test data. For processing, evaluate model step uses [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) container. It allows to select the appropriate instance type and instance count for processing the data. Evaluate model step is a [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) and utilizes *evaluate.py* script. It unpickles and reads the trained model from *model.tar.gz* from S3 bucket, which was output of train model step. It utilizes the test data from from prepare data step to evaluate the model and generates performance metrics (accuracy, area under curve) as output. As part of ProcessingStep, evaluate model step uses ProcessingInput as input and ProcessingOutput for output. The evaluation metrics are saved as .json file which is required for later steps related to configuring baseline step and configuring conditional step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd6c93-34ee-4b7e-a374-33a71657289b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure SageMaker Processing Job\n",
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=xgboost_container,\n",
    "    command=[\"python3\"],\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    base_job_name='evaluation',\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "# Specify where we'll store the model evaluation results so\n",
    "# that other steps can access those results\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json',\n",
    ")\n",
    "\n",
    "# Configure Pipeline Step - 'ProcessingStep'\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=data_preparation_step.properties.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/test',\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation', \n",
    "            source='/opt/ml/processing/evaluation',\n",
    "        ),\n",
    "    ],\n",
    "    code=\"s3://{}/aim321-demo-model-monitor-batch-transform/scripts/evaluation.py\".format(bucket),\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2961a-361f-43ac-9ccc-f637aa25674b",
   "metadata": {},
   "source": [
    "## 1-B. Configure Baseline Step for Data Drift Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f83bc-8edf-454d-9b53-d86009357bbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2561dd-dd4b-4aca-86c9-494048e9deda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "![Step5](./images/AIM321-Baseline-Data-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57850746-efbf-4829-81f8-281db44e4fd1",
   "metadata": {},
   "source": [
    "In order to monitor the model and data, a baseline is required. Baseline step sets the required baseline for data quality using [QualityCheckStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.quality_check_step.QualityCheckStep). Data Quality Baseline Job has two key parameters - data_quality_check_config and check_job_config. check_job_config allows to select the appropriate instance type and instance count for processing data quality check using CheckJobConfig. data_quality_check_config  sets the input path for the training data from previous prepare data step as well as path for output within S3. As output, QualityCheckStep generates two .json files, statistics.json and constraints.json which are saved in S3 buckets. statistics.json contains statistics (like mean, sum, standard deviation, min, max) of each of the feature columns of the training dataset. constraints.json contain information like completeness and non-negative or not for the feature columns of training dataset. Statistics and constraints form key components for setting baseline for data quality monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5ee15-bfbe-4ce4-9683-2e7ecf55f36c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the Data Quality Baseline Job\n",
    "\n",
    "# Configure the transient compute environment\n",
    "check_job_config = CheckJobConfig(\n",
    "    role=role_arn,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    volume_size_in_gb=120,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "# Configure the data quality check input (training data), dataset format, and S3 output path\n",
    "data_quality_check_config = DataQualityCheckConfig(\n",
    "    baseline_dataset=data_preparation_step.properties.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False, output_columns_position=\"START\"),\n",
    "    output_s3_uri=Join(on='/', values=['s3:/', bucket, bucket_prefix, ExecutionVariables.PIPELINE_EXECUTION_ID, 'dataqualitycheckstep'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95db497-b9b7-4e6e-aa82-e19f3a51fe12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure Pipeline Step - 'QualityCheckStep'\n",
    "baseline_model_data_step = QualityCheckStep(\n",
    "        name=\"DataQualityCheckStep\",\n",
    "        # skip_check, indicates a baselining job\n",
    "        skip_check=True,\n",
    "        register_new_baseline=True,\n",
    "        quality_check_config=data_quality_check_config,\n",
    "        check_job_config=check_job_config,\n",
    "        model_package_group_name=model_package_group_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a82fcc0-c458-4a4d-a364-374724895fe9",
   "metadata": {},
   "source": [
    "## 1-B. Configure Steps to Package & Register Model Version\n",
    "\n",
    "Configure steps to package and register model version are broken down in two steps,\n",
    "\n",
    "1. Package Model Step\n",
    "2. Register Model Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062bf2b-0270-4ca0-8dac-53970629777d",
   "metadata": {},
   "source": [
    "![Step6](./images/AIM321-Package-Register-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e4132-8995-4831-bd8d-3c30e49cb65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Package & Register Model Steps: Configure step to create and register model\n",
    "\n",
    "Configure metrics captured, package model for inference, & register model version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3c6e3-bf5d-4039-a1e2-01039e4ddad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Package Model Step\n",
    "\n",
    "Package model step serves the purpose of packaging the model and baseline for model registry. [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) is used to specify paths to .json files within S3 buckets for model evaluation metric from evaluate model step, and for statistic, constraints files from baseline step. These are used for model registry. Model artifacts are specified from train model step. \n",
    "\n",
    "As part of the pipeline, [ModelStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.model_step.ModelStep) configures model package model for inference using model object, model.create().  model.create() allows to specify the stance to run the package model step. This step is required as in Part 2 model monitor will be performed for batch inference job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bfdf2-dd28-4b4e-af67-e130a0770682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify model metric and drift baseline metadata to register\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri='{}/evaluation.json'.format(\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "        ),\n",
    "        content_type='application/json',\n",
    "    ),\n",
    "    model_data_statistics=MetricsSource(\n",
    "            s3_uri=baseline_model_data_step.properties.CalculatedBaselineStatistics,\n",
    "            content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "            s3_uri=baseline_model_data_step.properties.CalculatedBaselineConstraints,\n",
    "            content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=baseline_model_data_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=baseline_model_data_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=estimator.training_image_uri(),\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    entry_point=estimator.entry_point,\n",
    "    role=role_arn,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26f81a-4249-4e09-8a6a-7a30c5132266",
   "metadata": {},
   "source": [
    "#### 2. Register Model Step\n",
    "\n",
    "Register model step registers model version using metadata, baseline using model object, [model.register()](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.register). model.register() brings the metadata related to model and baseline using ModelMetrics This step uses ModelStep to register model and baseline information to model registry. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902269de-bc00-4093-bb65-b89e0ffcadab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure step to package model for inference using Model object: model.create()\n",
    "\n",
    "step_args = model.create(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "\n",
    "create_model_step = ModelStep(\n",
    "    name=\"CustomerChurnCreateModel\",\n",
    "    step_args=step_args,\n",
    ")\n",
    "\n",
    "\n",
    "# Configure step to register model version using metadata and Model object: model.register()\n",
    "model_registry_args = model.register(\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    customer_metadata_properties={\"ModelName\": create_model_step.properties.ModelName},\n",
    "    drift_check_baselines=drift_check_baselines,\n",
    "    approval_status='PendingManualApproval',\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "register_step = ModelStep(\n",
    "    name='RegisterModel',\n",
    "    step_args=model_registry_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de67cb3-35e3-45f8-8fbd-d4fa9e4118d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1-C. Conditional Step: Configure step to evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b83847-66c2-4597-8171-20e8005bb328",
   "metadata": {},
   "source": [
    "Conditional step is a performance check step which checks the quality of the trained model based on the evaluate model step. It reads the *evaluation.json* file and checks the whether the model accuracy is greater than certain threshold using ConditionGreaterThanOrEqualTo.  Only if the model accuracy is greater than the threshold (If true condition), the pipeline continues to process baseline step, package model step and register model step using [ConditionStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#conditionstep). If the condition is not met for performance check, the pipeline fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563ee91-284f-4106-b8ed-baacb3f35bb0",
   "metadata": {},
   "source": [
    "![Step4](./images/AIM321-Conditional-Step-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa758a-59b3-4972-b94f-9862b24864c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Condition step for evaluating model quality and branching execution\n",
    "\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path='binary_classification_metrics.accuracy.value',\n",
    "    ),\n",
    "    right=0.4,\n",
    ")\n",
    "condition_step = ConditionStep(\n",
    "    name='PerformanceConditionalCheck',\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[baseline_model_data_step,create_model_step, register_step],\n",
    "    else_steps=[],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6929ef0f-7646-4cbc-91b6-9918bbbcb3d4",
   "metadata": {},
   "source": [
    "At this point, all the seven steps of train and baseline pipeline are defined and configured.\n",
    "\n",
    "1. Prepare Data Step\n",
    "2. Train Model Step\n",
    "3. Evaluate Model Step\n",
    "4. Conditional Step for Performance Check.\n",
    "5. Baseline Step\n",
    "6. Package Model Step\n",
    "7. Register Model Step\n",
    "\n",
    "Baseline step, package model step and register model step are nested within the conditional step, when the performance check condition is satisfied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd90e14-5bde-4d3e-9a27-32ba056093a9",
   "metadata": {},
   "source": [
    "![Create](./images/AIM321-Pipeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bd944-becc-47fc-a426-e5a2cc586ac6",
   "metadata": {},
   "source": [
    "Putting it all together, Pipeline() sets up the train and baseline pipeline with the steps and their configurations. training_pipeline.upsert() creates the pipeline with pipeline role. training_pipeline.start() starts executing the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7462d-b3a0-48c8-8db1-18b3d1c40f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = 'aim321-train-baseline-pipeline-1'\n",
    "step_list = [\n",
    "             data_preparation_step,\n",
    "             training_step,\n",
    "             evaluation_step,\n",
    "             condition_step]\n",
    "\n",
    "training_pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "      ],\n",
    "    steps=step_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e0b05-5f62-4553-856c-47bc2f558f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Viewing the pipeline definition will all the string variables interpolated may help debug pipeline bugs. It is commented out here due to length.\n",
    "#json.loads(training_pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88783197-ce81-406d-bcb5-329cf0d6c0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: If an existing pipeline has the same name it will be overwritten.\n",
    "training_pipeline.upsert(role_arn=role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a590e8-459a-4125-b4ce-6e703c3cfb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = training_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac082fd-fcdf-44b1-83d2-8ffca81cb79b",
   "metadata": {},
   "source": [
    "Once the pipeline starts executing, the status of the pipeline (executing, succeeded or failed) can be found browsing “Pipelines” within SageMaker Studio. The pipeline shows the Directed acyclic graph (DAG) with the 7 steps of the pipeline. For each step, it shows related information like input, output, log, information, overview, settings, details depending on the configuration of the step. The diagram below shows which steps from the pipeline process relate to the steps of the pipeline DAG. Once the train and baseline pipeline executes successfully, it registers the trained model as part of the model group of model registry. Opening “Model registry” within SageMaker Studio, the model group name can be found with its status. Clicking on the appropriate model group name, shows the model version and status. The status of the model has to be updated to “Approved”, as required by the batch inference and model monitor pipeline in Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f0c36-9f4b-4f1d-91e2-0bd7da4dc93f",
   "metadata": {},
   "source": [
    "# View Baseline Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cdfdce-62d7-4006-a58b-824971a4db3c",
   "metadata": {},
   "source": [
    "This works only after model pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee0d4f-cb57-4958-9cff-7bf7a89396b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import MonitoringExecution\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "monitoring_step = [step for step in execution.list_steps() if \"QualityCheck\" in step[\"Metadata\"]][0]\n",
    "s3_baseline_statistics=monitoring_step[\"Metadata\"][\"QualityCheck\"][\"BaselineUsedForDriftCheckStatistics\"]\n",
    "print(\"S3 URI FOR BASELINE STATISTICS ==>\", s3_baseline_statistics)\n",
    "s3_baseline_constraints=monitoring_step[\"Metadata\"][\"QualityCheck\"][\"BaselineUsedForDriftCheckConstraints\"]\n",
    "print(\"S3 URI FOR BASELINE CONSTRAINTS ==>\", s3_baseline_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c24bf-c804-40db-88bf-5ca3977cd29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "statistics = json.loads(S3Downloader.read_file(s3_baseline_statistics))\n",
    "constraints = json.loads(S3Downloader.read_file(s3_baseline_constraints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306f82f-a61b-4cb5-92dd-6dbc68cd6d9f",
   "metadata": {},
   "source": [
    "### View Baseline Constraints\n",
    "\n",
    "SageMaker Model Monitor will automatically identify data quality constraints that can be used as-is or customized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b23b64-eef8-4d3f-ab5d-ab04465c5fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "constraints_df = pd.json_normalize(constraints, record_path=['features'])\n",
    "constraints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04d671-f2af-4c7a-a385-34a08d7bc86b",
   "metadata": {},
   "source": [
    "### View Baseline Statistics\n",
    "\n",
    "SageMaker Model Monitor will automatically identify statistical calculations for each feature in the baseline dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d54fb-40ac-406b-8e39-a1b52dd51a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "statistics_df = pd.json_normalize(statistics, record_path=['features'])\n",
    "statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954106b-4951-403f-9c5d-332ad72d48df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
